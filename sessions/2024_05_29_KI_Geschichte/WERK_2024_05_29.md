---
theme: werkstatt
---
## Künstliche Intelligenz & Manipulation

#### Bauhaus Digitalwerkstatt

---

<!-- slide bg="pink" -->

### News Alert

> ![News Image](https://cdn.netzpolitik.org/wp-upload/2024/05/imago125252329_1600-860x484.jpg)
> 
> ##### [Predictive Policing: Gefährliche Lücke in der KI-Verordnung](https://netzpolitik.org/2024/predictive-policing-gefaehrliche-luecke-in-der-ki-verordnung/)
---
### Geschichte der KI
![[ZeitstrahlGeschichte.png]]
--
#### Theseus
> - Erfindung einer mechanischen Maus, die in der Lage war, ein Labyrinth zu erforschen, sich darin zu orientieren und den Weg nach draussen zu finden.
> - Anwendung von "Trial and Error"
> - von Claude Shannon
--
#### Dartmouth Konferenz
> - erstmals tauchte der Begriff “künstlichen Intelligenz” auf
> - gilt als die Geburtsstunde der künstlichen Intelligenz als ein akademisches Fachgebiet

--
#### Turing Test
> - von Alan Turing, der Begründer der modernen Computerwissenschaft
> - *“Kann eine Maschine denken?”*
> - Turing-Test: Eine Maschine gilt dann als intelligent, wenn sie in der Lage war, einem menschlichen Gesprächspartner im Rahmen einer textbasierten Unterhaltung “vorzugaukeln” ein Mensch zu sein
--
#### Perzeptron
> Modell eines neuronalen Netzes
> Frank Rosenblatt
--
#### IBM Deep Blue
> - Schachcomputer schlägt Schachweltmeister Garri Kasparow
> - basiert auf symbolischer KI (feste Regel, Logik)
--
#### Deep Learning
> - basierend auf neuronalen Netzen
> - Computerprogramm AlphaGo schlägt Weltmeister Lee Sedol
---
<!-- slide bg="cyan" -->

#### Knobelei
> Wie lassen sich 8 Damen auf einem gewöhnlichen (8×8 Felder großen) Schachbrett anordnen, sodass sich keine der zwei Damen gegenseitig schlagen können?
--
#### Lösung
- 92 mögliche Lösungen (12 grundsätzlich Verschieden)
![Image](https://raetselgeist.de/wp-content/uploads/2024/01/Acht-Damenproblem-Loesung-e1705510345248.png)
---
<!-- slide bg="yellow" -->

### Maschinelles Lernen
##### Künstliche Intelligenz in der Informatik

---
#### Was ist eigentlich ein Algorithmus? 

* **Definition**: Ein Algorithmus ist eine **eindeutige Handlungsanweisung** zur Lösung eines Problems. 
* **Wortursprung**: Der Begriff kommt vom persischen Mathematiker Al-Chwarizmi. 
* **Beispiel**: Ein Rezept zum Kuchenbacken ist ein Algorithmus.

---

#### Was machen also Programmierer?
 
#### und was macht maschinelles Lernen?

---

### Unterschied Klassische Algorithmen und Maschinelles Lernen
- **Klassische Algorithmen**: Folgen festen Regeln, z.B. Sortieralgorithmen. 
- **KI-Algorithmen**: Können aus Daten lernen und sich anpassen. 
- **Beispiel**: Ein Spam-Filter, der sich verbessert, je mehr E-Mails er analysiert.

---

![[Pasted image 20240529172431.png]]

---

![[Pasted image 20240529172608.png]]

---

![](http://media2.s-nbcnews.com/i/newscms/2016_10/1008761/chihuahua-muffin-today-160311-tease-02_15277fe1b7a8c911f94700f866189fc2.jpg)

---
#### Bedeutung von Daten für maschinelles Lernen 
- **Daten**: Grundlage für das Training von KI-Modellen. 
- **Je mehr, desto besser**: Größere Datenmengen führen oft zu besseren Modellen.
- **Beispiel**: Bilder von Muffins und Hunden, um ein Modell zu trainieren, das beide Dinge unterscheiden kann.

---

#### Maschinelles Lernen in drei Phasen 
##### > Training, Testing, Evaluation
--
- **Training**: Der Prozess, bei dem das Modell aus Daten lernt. 
	- **Trainingsdaten**: Daten, die zum Lernen verwendet werden. 
--
- **Test**: Überprüfung des Modells auf neuen, ungesehenen Daten. 
	- **Testdaten**: Daten, die nicht zum Training verwendet wurden. 
--
- **Evaluation**: Bewertung der Leistung des Modells.
	- **Metriken**: Genauigkeit, Präzision, Recall etc.
---
#### Cognitive Bias

> confirmation bias: die eigene Vorstellung beeinflussen das eigene Handeln und führen dazu, dass man selbst in seiner Meinung wieder bestätigt wird

--
##### biased search for information
> "are dogs better than cats?"

> "are cats better than dogs?"

---

![](https://upload.wikimedia.org/wikipedia/commons/1/18/Cognitive_Bias_Codex_-_180%2B_biases%2C_designed_by_John_Manoogian_III_%28jm3%29.jpg)

--
![[TooMuchInformation.png]]

--
![[NotEnoughMeaning.png]]

--
![[NeedToActFast.png]]

--
![[WhatShouldWeRemember.png]]

---
<!-- slide bg="cyan" -->

#### Knobelei
> Ihr konstruiert kleine und schnelle Frachtflugzeuge, die Hilfsgüter in ein Krisengebiet transportieren. Leider müssen die Flugzeuge über feindliches Gebiet fliegen, werden dabei angeschossen und einige stürzen dabei auch ab. Ihr erhaltet aus dem Flugzeughanger eine Skizze mit den häufigsten Einschusslöchern.

--
<!-- slide bg="cyan" -->
 ![Image|500](http://blog.idonethis.com/wp-content/uploads/2018/07/image-11-2.png)

> Basierend auf der Skizze, wie könnt ihr die Flugzeuge verbessern und zukünftige Abstürze verhindern?

---

<!-- slide bg="cyan" -->

### Knobelei Lösung

--
<!-- slide bg="cyan" -->

 ![|500](https://ludattel.de/survivorship_solution.png)

> Es müssen genau die Stellen verstärkt werden, an denen es keine Einschusslöcher gibt.
---
### Bias von Daten
---
![Image](https://lh7-us.googleusercontent.com/9CkcTmVWFPGRSaVZ0v3LxDy_ELYyG5EzrNSwltJesy1t4a22B1YJZyWj4uNQcJW6BOFzmgOiueYatbUOga24KJ-Fa8Pq0NREj1r2qXxlUsHY-jWhqe2GfAuSwDKM8QTRRCR9MCaxfm6bdpJU623NeQ=s2048)

![Image](https://lh7-us.googleusercontent.com/Ft5hr-xciLmuSExwxgIBeAjxqD-QDWT_-Fj59ACZ5V3NWjcfRzdMip0qJ8j7WvmYbf2IWdKGdKjTZYyLYbtidiylUrbedmAIGVzIxvA0iRjU11eamnpCbrTG0RNRMbI4Kdk6cq27MY6NqSW48F6Hgg=s2048)

---

- **Bias**: Verzerrungen in den Daten, die zu unfairen oder falschen Ergebnissen führen. 
- **Beispiele für Bias**: 
	- Geschlechterbias: Ein Modell bevorzugt Männer gegenüber Frauen. 
	- ethnischer Bias: Ein Modell erkennt Gesichter bestimmter Ethnien besser als andere. 
- **Lösungen**: Diversifizierung der Daten, bewusste Modellierung und regelmäßige Überprüfungen.
---
### teachable Maschine
https://teachablemachine.withgoogle.com/

---
<!-- slide bg="blue" -->
# Pause

---
#### Limitation von KI-Modellen

* **Overfitting**: Das Modell lernt zu gut auf den Trainingsdaten und ist nicht gut bei neuen Daten. 
* **Symptome**: Hohe Genauigkeit bei Trainingsdaten, niedrige Genauigkeit bei Testdaten. 
* **Underfitting**: Das Modell lernt nicht genug aus den Trainingsdaten. 
* **Symptome**: Niedrige Genauigkeit bei sowohl Trainings- als auch Testdaten. 
---